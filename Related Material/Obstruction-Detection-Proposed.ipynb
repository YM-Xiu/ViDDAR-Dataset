{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obstruction Detection - Proposed Method with GPT-4o\n",
    "\n",
    "only use the mask with highest confidence\n",
    "\n",
    "detection accuracy = 94.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, File, UploadFile, Form\n",
    "from fastapi.responses import FileResponse, StreamingResponse, JSONResponse\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "import subprocess\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from lang_sam import LangSAM\n",
    "import torch\n",
    "import cv2\n",
    "import base64\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import queue\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "322\n",
      "322\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "root_dir = '...'\n",
    "\n",
    "mask_dir = root_dir + 'augmented content masks/' # this is the mask of ar content\n",
    "ar_dir = root_dir + 'augmented images/'\n",
    "img_dir = root_dir + 'raw img all/'\n",
    "\n",
    "# data_csv = '/home/yanming/Workspace/Detrimental Detection/Dataset Folder v1 - 119 imgs/adjusted_dataset.csv'\n",
    "ar_csv = '.../dataset-gt-no-laptop.csv'\n",
    "\n",
    "# data = pd.read_csv(data_csv)\n",
    "ar_data = pd.read_csv(ar_csv)\n",
    "\n",
    "print(len(os.listdir(mask_dir)))\n",
    "print(len(os.listdir(ar_dir)))\n",
    "print(len(os.listdir(img_dir)))\n",
    "\n",
    "print(len(ar_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LangSAM(sam_type=\"vit_b\")\n",
    "\n",
    "result_csv = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# account 1: google login\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "api_key = '...'\n",
    "\n",
    "question = \"Identify the key object that need people's attention or safety inspection in the image. \\\n",
    "            Give only one object that you think is important to be noticed, \\\n",
    "            output its name only and do not provide any other information. \\\n",
    "            The objects can be caution information signs, electrical devices, safety equipments, etc. \\\n",
    "            If you think a color is important, you can also mention the color, such as red box, but \\\n",
    "            try to be precise and describe the object with no more than 4 words. \"   \n",
    "            \n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "no_prediction = 0\n",
    "\n",
    "rand_thres_flag = True\n",
    "largest_flag = True\n",
    "\n",
    "for i in range(len(ar_data)):\n",
    "    \n",
    "    # random threshold range from 0.15 to 0.25\n",
    "    if rand_thres_flag == False:\n",
    "        rand_thres = 0.2\n",
    "    else:\n",
    "        rand_thres = np.random.uniform(0.175, 0.225)\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    image_name = ar_data['File Name'][i]\n",
    "    \n",
    "    # print(image_name)\n",
    "    \n",
    "    ar_mask_name = ar_data['File Name'][i] # Help_station_4.png\n",
    "    ar_mask_name = 'mask_AR_' + ar_mask_name # AR_mask_Help_station_4.png\n",
    "\n",
    "    img = Image.open(os.path.join(img_dir, image_name))\n",
    "    \n",
    "    img_enc = encode_image(os.path.join(img_dir, image_name))\n",
    "    \n",
    "    payload = {\n",
    "        # ! This is the model for GPT-4 Vision\n",
    "        # \"model\": \"gpt-4-vision-preview\",\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": question\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{img_enc}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    \n",
    "    bad_response = True\n",
    "    bad_response_list = ['sorry', 'however', 'there is no', 'there are no', \\\n",
    "    'too', 'blurred', 'blurry', 'can\\'t', 'is not', 'isn\\'t', 'it\\'s', 'difficult']\n",
    "    \n",
    "    while bad_response:\n",
    "\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        \n",
    "        # ! if there's no 'error' in the keys:\n",
    "        if 'error' in response.json().keys():\n",
    "            print('Error!')\n",
    "            print(response.json())\n",
    "            continue\n",
    "        text_response = response.json()['choices'][0]['message']['content']\n",
    "        \n",
    "        # remove \" and ' in the response\n",
    "        text_response = text_response.replace('\\\"', '')\n",
    "        text_response = text_response.replace(\"\\'\", '')\n",
    "        \n",
    "        if any(bad in text_response for bad in bad_response_list) == False:\n",
    "            bad_response = False\n",
    "            break\n",
    "    \n",
    "    \n",
    "    # prompt = prompt_data[prompt_data['File Name'] == image_name]['Prompt'].values[0]\n",
    "    prompt = text_response\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # this mask is for AR content\n",
    "    ar_mask = Image.open(os.path.join(mask_dir, ar_mask_name))\n",
    "    \n",
    "    file_name = ar_data['File Name'][i]\n",
    "    \n",
    "    \n",
    "    true_object = ar_data['Object Name'][i]\n",
    "    \n",
    "    ar_name = ar_data['File Name'][i]\n",
    "    \n",
    "    truth = ar_data[ar_data['File Name'] == ar_name]['obstruction'].values[0]\n",
    "    truth = True if truth == 'yes' else False\n",
    "    \n",
    "    sam_masks, sam_boxes, sam_phrases, sam_logits = model.predict(img, prompt)\n",
    "    \n",
    "    \n",
    "    # print(sam_logits)\n",
    "    # print(sam_phrases) \n",
    "    \n",
    "    \n",
    "    if len(sam_masks) == 0:\n",
    "        print(f\"No objects of the '{prompt}' prompt detected in the image.\")\n",
    "        no_prediction += 1\n",
    "        correct = 0\n",
    "        # write the result to the csv\n",
    "        with open(result_csv, 'a') as f:\n",
    "            f.write(f\"{file_name},{true_object},{prompt},{'N/A'},{'N/A'},{correct}\\n\")\n",
    "            \n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        if largest_flag:\n",
    "            # only leave the mask with the highest confidence\n",
    "            max_logit = max(sam_logits)\n",
    "            sam_masks = [mask for mask, logit in zip(sam_masks, sam_logits) if logit == max_logit]\n",
    "            boxes = [box for box, logit in zip(sam_boxes, sam_logits) if logit == max_logit]\n",
    "            phrases = [phrase for phrase, logit in zip(sam_phrases, sam_logits) if logit == max_logit]\n",
    "            sam_logits = [logit for logit in sam_logits if logit == max_logit]\n",
    "            \n",
    "        mean_confidence = np.mean(sam_logits)\n",
    "        sam_masks_np = [m.squeeze().cpu().numpy() for m in sam_masks]\n",
    "    \n",
    "        # generate a overall mask\n",
    "        overall_mask = np.zeros_like(sam_masks_np[0])\n",
    "        for m in sam_masks_np:\n",
    "            overall_mask += m\n",
    "            \n",
    "        # this mask is for real objects\n",
    "        overall_mask[overall_mask > 1] = 1\n",
    "        \n",
    "        # calculate the intersection\n",
    "        intersection = np.logical_and(overall_mask, ar_mask)\n",
    "        real_area = np.sum(overall_mask)\n",
    "        \n",
    "        if intersection.sum() / real_area > rand_thres:\n",
    "            pred = True\n",
    "        else:\n",
    "            pred = False\n",
    "            \n",
    "        if pred == truth:\n",
    "            correct = 1\n",
    "            total += 1\n",
    "        else:\n",
    "            correct = 0\n",
    "            \n",
    "        if pred == True and truth == True:\n",
    "            tp += 1\n",
    "        elif pred == False and truth == False:\n",
    "            tn += 1\n",
    "        elif pred == True and truth == False:\n",
    "            fp += 1\n",
    "        elif pred == False and truth == True:\n",
    "            fn += 1\n",
    "        \n",
    "        # write the result to the csv\n",
    "        with open(result_csv, 'a') as f:\n",
    "            f.write(f\"{file_name},{true_object},{prompt},{mean_confidence},{truth},{pred},{correct}\\n\")\n",
    "            \n",
    "        # print(f\"Prediction: {pred}, Truth: {truth}\")\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # if i % 10 == 0:\n",
    "    #     print(f\"Finished {i} images.\")\n",
    "    # if i == 0:\n",
    "    #     break\n",
    "    \n",
    "# print(f\"Accuracy: {total / len(ar_data)}\")\n",
    "# print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}, No Prediction: {no_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n",
      "False\n",
      "1.0\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "TP: 134, TN: 154, FP: 5, FN: 11, No Prediction: 0\n",
      "Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "df = pd.read_csv(result_csv)\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "no_prediction = 0\n",
    "\n",
    "print(df['Prediction'][20])\n",
    "print(df['Score'][0])\n",
    "\n",
    "print(type(df['Prediction'][20]))\n",
    "print(type(df['Score'][0]))\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # print(df['Prediction'][i])\n",
    "    # print(df['Score'][i])\n",
    "    \n",
    "    if str(df['Prediction'][i]) == 'nan':\n",
    "        no_prediction += 1\n",
    "    elif df['Prediction'][i] == 'True' and df['Score'][i] == 1:\n",
    "        tp += 1\n",
    "    elif df['Prediction'][i] == 'False' and df['Score'][i] == 1:\n",
    "        tn += 1\n",
    "    elif df['Prediction'][i] == 'True' and df['Score'][i] == 0:\n",
    "        fp += 1\n",
    "    elif df['Prediction'][i] == 'False' and df['Score'][i] == 0:\n",
    "        fn += 1\n",
    "        \n",
    "print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}, No Prediction: {no_prediction}\")\n",
    "print(f\"Accuracy: {(tp + tn) / len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangSAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
